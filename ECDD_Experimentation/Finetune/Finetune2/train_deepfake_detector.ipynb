{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Deepfake Detection Training Notebook\n",
                "\n",
                "This notebook trains a LaDeDa ResNet50 model to classify real vs diffusion-generated fake images.\n",
                "\n",
                "## Features:\n",
                "- âœ… **Early Stopping** - Stops when validation loss doesn't improve for 4 epochs\n",
                "- âœ… **Strong Data Augmentation** - Rotation, random crop, grayscale, color jitter\n",
                "- âœ… **Dropout** - 0.4 probability in classifier head\n",
                "- âœ… **Weight Decay** - 1e-3 for regularization\n",
                "- âœ… **Layer Freezing** - Only trains layer4 + classifier (~10% params)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup and Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import sys\n",
                "import json\n",
                "import random\n",
                "import io\n",
                "import time\n",
                "from pathlib import Path\n",
                "from dataclasses import dataclass, field\n",
                "from typing import Tuple, List, Dict, Optional\n",
                "\n",
                "import numpy as np\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "import torch.nn.functional as F\n",
                "from torch.utils.data import DataLoader, Dataset\n",
                "from torch.cuda.amp import autocast, GradScaler\n",
                "from torchvision.models import resnet50, ResNet50_Weights\n",
                "from PIL import Image, ImageOps, ImageFilter, ImageEnhance\n",
                "from tqdm.notebook import tqdm\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "print(f\"PyTorch version: {torch.__version__}\")\n",
                "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "@dataclass\n",
                "class TrainingConfig:\n",
                "    \"\"\"Training configuration.\"\"\"\n",
                "    # Paths\n",
                "    data_path: str = \"./newfinetune2\"\n",
                "    output_dir: str = \"./outputs\"\n",
                "    \n",
                "    # Training parameters\n",
                "    epochs: int = 30  # Max epochs (early stopping will likely trigger before)\n",
                "    batch_size: int = 16\n",
                "    lr: float = 3e-5\n",
                "    weight_decay: float = 1e-3  # Strong weight decay for regularization\n",
                "    \n",
                "    # Early stopping\n",
                "    early_stopping_patience: int = 4  # Stop if no improvement for 4 epochs\n",
                "    \n",
                "    # Model\n",
                "    freeze_layers: List[str] = field(default_factory=lambda: [\"conv1\", \"layer1\", \"layer2\", \"layer3\"])\n",
                "    dropout_rate: float = 0.4  # Dropout for classifier head\n",
                "    \n",
                "    # Other\n",
                "    num_workers: int = 2\n",
                "    seed: int = 42\n",
                "\n",
                "\n",
                "@dataclass\n",
                "class AugmentConfig:\n",
                "    \"\"\"Augmentation configuration with stronger augmentations.\"\"\"\n",
                "    # Compression/degradation\n",
                "    jpeg_qualities: List[int] = field(default_factory=lambda: [30, 50, 75, 95])\n",
                "    resize_scales: List[float] = field(default_factory=lambda: [0.5, 0.75, 1.25, 1.5])\n",
                "    blur_sigmas: List[float] = field(default_factory=lambda: [0.5, 1.0, 1.5])\n",
                "    noise_sigmas: List[float] = field(default_factory=lambda: [3.0, 6.0, 10.0])\n",
                "    \n",
                "    # Color augmentation - stronger jitter\n",
                "    brightness_range: Tuple[float, float] = (0.7, 1.3)\n",
                "    contrast_range: Tuple[float, float] = (0.7, 1.3)\n",
                "    saturation_range: Tuple[float, float] = (0.7, 1.3)\n",
                "    hue_range: Tuple[float, float] = (-0.1, 0.1)\n",
                "    \n",
                "    # Geometric augmentations\n",
                "    rotation_range: Tuple[float, float] = (-15, 15)\n",
                "    random_crop_scale: Tuple[float, float] = (0.8, 1.0)\n",
                "    random_crop_ratio: Tuple[float, float] = (0.9, 1.1)\n",
                "    \n",
                "    # Probabilities\n",
                "    p_jpeg: float = 0.5\n",
                "    p_resize: float = 0.3\n",
                "    p_blur: float = 0.3\n",
                "    p_noise: float = 0.3\n",
                "    p_color: float = 0.5\n",
                "    p_flip: float = 0.5\n",
                "    p_rotation: float = 0.4\n",
                "    p_grayscale: float = 0.1\n",
                "    p_random_crop: float = 0.3\n",
                "\n",
                "\n",
                "# Initialize configs\n",
                "config = TrainingConfig()\n",
                "augment_config = AugmentConfig()\n",
                "\n",
                "# Constants\n",
                "TARGET_SIZE = (256, 256)\n",
                "IMAGENET_MEAN = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
                "IMAGENET_STD = np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
                "\n",
                "print(\"Configuration loaded:\")\n",
                "print(f\"  - Epochs: {config.epochs} (with early stopping patience={config.early_stopping_patience})\")\n",
                "print(f\"  - Batch size: {config.batch_size}\")\n",
                "print(f\"  - Learning rate: {config.lr}\")\n",
                "print(f\"  - Weight decay: {config.weight_decay}\")\n",
                "print(f\"  - Dropout rate: {config.dropout_rate}\")\n",
                "print(f\"  - Frozen layers: {config.freeze_layers}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Set Random Seed"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def set_seed(seed: int = 42):\n",
                "    \"\"\"Set random seeds for reproducibility.\"\"\"\n",
                "    random.seed(seed)\n",
                "    np.random.seed(seed)\n",
                "    torch.manual_seed(seed)\n",
                "    torch.cuda.manual_seed_all(seed)\n",
                "    torch.backends.cudnn.benchmark = True\n",
                "    torch.backends.cudnn.deterministic = False\n",
                "\n",
                "set_seed(config.seed)\n",
                "print(f\"Random seed set to {config.seed}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Data Loading Functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "@dataclass\n",
                "class ImageMetadata:\n",
                "    \"\"\"Metadata for a single image.\"\"\"\n",
                "    path: Path\n",
                "    label: int  # 0 = real, 1 = fake\n",
                "    image_id: str\n",
                "\n",
                "    @classmethod\n",
                "    def from_path(cls, path: Path, label: int):\n",
                "        return cls(path=path, label=label, image_id=path.stem)\n",
                "\n",
                "\n",
                "def load_split(data_root: Path, split: str) -> List[ImageMetadata]:\n",
                "    \"\"\"Load images from a split directory.\"\"\"\n",
                "    images = []\n",
                "    split_dir = data_root / split\n",
                "    \n",
                "    for label, class_name in [(0, \"real\"), (1, \"fake\")]:\n",
                "        class_dir = split_dir / class_name\n",
                "        if not class_dir.exists():\n",
                "            continue\n",
                "        \n",
                "        for ext in (\"*.jpg\", \"*.jpeg\", \"*.png\", \"*.JPG\", \"*.JPEG\", \"*.PNG\"):\n",
                "            for path in class_dir.glob(ext):\n",
                "                images.append(ImageMetadata.from_path(path, label))\n",
                "    \n",
                "    return images\n",
                "\n",
                "print(\"Data loading functions defined.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Augmentation Pipeline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def jpeg_compress(image: Image.Image, quality: int) -> Image.Image:\n",
                "    if image.mode != \"RGB\":\n",
                "        image = image.convert(\"RGB\")\n",
                "    buffer = io.BytesIO()\n",
                "    image.save(buffer, format=\"JPEG\", quality=quality, subsampling=0)\n",
                "    buffer.seek(0)\n",
                "    out = Image.open(buffer)\n",
                "    out.load()\n",
                "    buffer.close()\n",
                "    return out\n",
                "\n",
                "\n",
                "def resize_chain(image: Image.Image, scale: float) -> Image.Image:\n",
                "    w, h = image.size\n",
                "    new_w = max(1, int(w * scale))\n",
                "    new_h = max(1, int(h * scale))\n",
                "    image = image.resize((new_w, new_h), Image.Resampling.BILINEAR)\n",
                "    image = image.resize((w, h), Image.Resampling.BILINEAR)\n",
                "    return image\n",
                "\n",
                "\n",
                "def gaussian_blur(image: Image.Image, sigma: float) -> Image.Image:\n",
                "    return image.filter(ImageFilter.GaussianBlur(radius=sigma))\n",
                "\n",
                "\n",
                "def add_sensor_noise(image: Image.Image, sigma: float) -> Image.Image:\n",
                "    arr = np.asarray(image, dtype=np.float32)\n",
                "    noise = np.random.normal(0, sigma, arr.shape)\n",
                "    noisy = np.clip(arr + noise, 0, 255).astype(np.uint8)\n",
                "    return Image.fromarray(noisy)\n",
                "\n",
                "\n",
                "def adjust_brightness_contrast(image: Image.Image, brightness: float, contrast: float) -> Image.Image:\n",
                "    arr = np.asarray(image, dtype=np.float32)\n",
                "    arr = arr * brightness\n",
                "    mean = arr.mean()\n",
                "    arr = (arr - mean) * contrast + mean\n",
                "    return Image.fromarray(np.clip(arr, 0, 255).astype(np.uint8))\n",
                "\n",
                "\n",
                "def adjust_saturation(image: Image.Image, factor: float) -> Image.Image:\n",
                "    enhancer = ImageEnhance.Color(image)\n",
                "    return enhancer.enhance(factor)\n",
                "\n",
                "\n",
                "def adjust_hue(image: Image.Image, factor: float) -> Image.Image:\n",
                "    if image.mode != \"RGB\":\n",
                "        image = image.convert(\"RGB\")\n",
                "    arr = np.asarray(image, dtype=np.float32) / 255.0\n",
                "    cos_h = np.cos(factor * np.pi)\n",
                "    sin_h = np.sin(factor * np.pi)\n",
                "    r, g, b = arr[:,:,0], arr[:,:,1], arr[:,:,2]\n",
                "    new_r = r * (0.299 + 0.701*cos_h + 0.168*sin_h) + g * (0.587 - 0.587*cos_h + 0.330*sin_h) + b * (0.114 - 0.114*cos_h - 0.497*sin_h)\n",
                "    new_g = r * (0.299 - 0.299*cos_h - 0.328*sin_h) + g * (0.587 + 0.413*cos_h + 0.035*sin_h) + b * (0.114 - 0.114*cos_h + 0.292*sin_h)\n",
                "    new_b = r * (0.299 - 0.300*cos_h + 1.250*sin_h) + g * (0.587 - 0.588*cos_h - 1.050*sin_h) + b * (0.114 + 0.886*cos_h - 0.203*sin_h)\n",
                "    result = np.stack([new_r, new_g, new_b], axis=2)\n",
                "    result = np.clip(result * 255, 0, 255).astype(np.uint8)\n",
                "    return Image.fromarray(result)\n",
                "\n",
                "\n",
                "def random_rotation(image: Image.Image, angle: float) -> Image.Image:\n",
                "    return image.rotate(angle, resample=Image.Resampling.BILINEAR, expand=False, fillcolor=(128, 128, 128))\n",
                "\n",
                "\n",
                "def random_resized_crop(image: Image.Image, scale: Tuple[float, float], ratio: Tuple[float, float]) -> Image.Image:\n",
                "    w, h = image.size\n",
                "    area = w * h\n",
                "    target_area = random.uniform(scale[0], scale[1]) * area\n",
                "    aspect_ratio = random.uniform(ratio[0], ratio[1])\n",
                "    new_w = int(round(np.sqrt(target_area * aspect_ratio)))\n",
                "    new_h = int(round(np.sqrt(target_area / aspect_ratio)))\n",
                "    if new_w <= w and new_h <= h:\n",
                "        x1 = random.randint(0, w - new_w)\n",
                "        y1 = random.randint(0, h - new_h)\n",
                "        image = image.crop((x1, y1, x1 + new_w, y1 + new_h))\n",
                "    return image.resize((w, h), Image.Resampling.LANCZOS)\n",
                "\n",
                "\n",
                "def to_grayscale(image: Image.Image) -> Image.Image:\n",
                "    return image.convert(\"L\").convert(\"RGB\")\n",
                "\n",
                "\n",
                "class AugmentationPipeline:\n",
                "    \"\"\"Augmentation pipeline for training.\"\"\"\n",
                "    \n",
                "    def __init__(self, config: AugmentConfig = None):\n",
                "        self.config = config or AugmentConfig()\n",
                "\n",
                "    def __call__(self, image: Image.Image) -> Image.Image:\n",
                "        if image.mode != \"RGB\":\n",
                "            image = image.convert(\"RGB\")\n",
                "        \n",
                "        c = self.config\n",
                "        \n",
                "        # Geometric augmentations\n",
                "        if random.random() < c.p_flip:\n",
                "            image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
                "        \n",
                "        if random.random() < c.p_rotation:\n",
                "            angle = random.uniform(*c.rotation_range)\n",
                "            image = random_rotation(image, angle)\n",
                "        \n",
                "        if random.random() < c.p_random_crop:\n",
                "            image = random_resized_crop(image, c.random_crop_scale, c.random_crop_ratio)\n",
                "        \n",
                "        # Compression/degradation\n",
                "        if random.random() < c.p_jpeg:\n",
                "            image = jpeg_compress(image, random.choice(c.jpeg_qualities))\n",
                "        \n",
                "        if random.random() < c.p_resize:\n",
                "            image = resize_chain(image, random.choice(c.resize_scales))\n",
                "        \n",
                "        if random.random() < c.p_blur:\n",
                "            image = gaussian_blur(image, random.choice(c.blur_sigmas))\n",
                "        \n",
                "        if random.random() < c.p_noise:\n",
                "            image = add_sensor_noise(image, random.choice(c.noise_sigmas))\n",
                "        \n",
                "        # Color augmentations\n",
                "        if random.random() < c.p_color:\n",
                "            image = adjust_brightness_contrast(image, random.uniform(*c.brightness_range), random.uniform(*c.contrast_range))\n",
                "            image = adjust_saturation(image, random.uniform(*c.saturation_range))\n",
                "            if random.random() < 0.5:\n",
                "                image = adjust_hue(image, random.uniform(*c.hue_range))\n",
                "        \n",
                "        # Random grayscale\n",
                "        if random.random() < c.p_grayscale:\n",
                "            image = to_grayscale(image)\n",
                "        \n",
                "        return image\n",
                "\n",
                "print(\"Augmentation pipeline defined.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Dataset and DataLoader"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class DeepfakeDataset(Dataset):\n",
                "    \"\"\"Dataset for deepfake detection.\"\"\"\n",
                "    \n",
                "    def __init__(self, images: List[ImageMetadata], augment: bool = True, augment_config: AugmentConfig = None):\n",
                "        self.images = tuple(images)\n",
                "        self.augment = augment\n",
                "        self.aug_pipeline = AugmentationPipeline(augment_config) if augment else None\n",
                "        \n",
                "        n_real = sum(1 for img in self.images if img.label == 0)\n",
                "        n_fake = sum(1 for img in self.images if img.label == 1)\n",
                "        aug_str = \"augmented\" if augment else \"no augmentation\"\n",
                "        print(f\"  Dataset: {len(self.images)} images (Real: {n_real}, Fake: {n_fake}) [{aug_str}]\")\n",
                "\n",
                "    def __len__(self):\n",
                "        return len(self.images)\n",
                "\n",
                "    def __getitem__(self, idx):\n",
                "        meta = self.images[idx]\n",
                "        \n",
                "        with Image.open(meta.path) as img:\n",
                "            img = ImageOps.exif_transpose(img)\n",
                "            img = img.convert(\"RGB\")\n",
                "        \n",
                "        if self.augment and self.aug_pipeline:\n",
                "            img = self.aug_pipeline(img)\n",
                "        \n",
                "        img = img.resize(TARGET_SIZE, Image.Resampling.LANCZOS)\n",
                "        arr = np.asarray(img, dtype=np.float32) / 255.0\n",
                "        arr = (arr - IMAGENET_MEAN) / IMAGENET_STD\n",
                "        tensor = torch.from_numpy(arr).permute(2, 0, 1).contiguous()\n",
                "        \n",
                "        return {\n",
                "            \"image\": tensor,\n",
                "            \"label\": torch.tensor(meta.label, dtype=torch.long),\n",
                "            \"image_id\": meta.image_id,\n",
                "        }\n",
                "\n",
                "\n",
                "def collate_fn(batch):\n",
                "    return {\n",
                "        \"image\": torch.stack([b[\"image\"] for b in batch], dim=0),\n",
                "        \"label\": torch.stack([b[\"label\"] for b in batch], dim=0),\n",
                "        \"image_id\": [b[\"image_id\"] for b in batch],\n",
                "    }\n",
                "\n",
                "print(\"Dataset class defined.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Model Definition"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class AttentionPooling(nn.Module):\n",
                "    \"\"\"Attention-based pooling over patch logits.\"\"\"\n",
                "    \n",
                "    def __init__(self, in_channels=2048, hidden_dim=512):\n",
                "        super().__init__()\n",
                "        self.attention_fc = nn.Sequential(\n",
                "            nn.Conv2d(in_channels, hidden_dim, kernel_size=1),\n",
                "            nn.ReLU(inplace=True),\n",
                "            nn.Conv2d(hidden_dim, 1, kernel_size=1),\n",
                "        )\n",
                "\n",
                "    def forward(self, features, patch_logits):\n",
                "        attn_scores = self.attention_fc(features)\n",
                "        B, _, H, W = attn_scores.shape\n",
                "        attn_flat = attn_scores.view(B, -1)\n",
                "        attn_flat = attn_flat - attn_flat.max(dim=1, keepdim=True)[0]\n",
                "        attn = F.softmax(attn_flat, dim=1).view(B, 1, H, W)\n",
                "        pooled = (patch_logits * attn).sum(dim=(2, 3))\n",
                "        return pooled, attn\n",
                "\n",
                "\n",
                "class LaDeDaResNet50(nn.Module):\n",
                "    \"\"\"LaDeDa-style ResNet50 for deepfake detection with dropout regularization.\"\"\"\n",
                "    \n",
                "    def __init__(self, pretrained=True, freeze_layers=None, dropout_rate=0.4):\n",
                "        super().__init__()\n",
                "        \n",
                "        base = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2 if pretrained else None)\n",
                "        \n",
                "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
                "        if pretrained:\n",
                "            with torch.no_grad():\n",
                "                self.conv1.weight.copy_(base.conv1.weight[:, :, 2:5, 2:5])\n",
                "        \n",
                "        self.bn1 = base.bn1\n",
                "        self.relu = base.relu\n",
                "        self.layer1 = base.layer1\n",
                "        self.layer2 = base.layer2\n",
                "        self.layer3 = base.layer3\n",
                "        self.layer4 = base.layer4\n",
                "        \n",
                "        # Dropout for regularization\n",
                "        self.dropout = nn.Dropout2d(p=dropout_rate)\n",
                "        \n",
                "        self.patch_classifier = nn.Conv2d(2048, 1, kernel_size=1)\n",
                "        self.attention_pool = AttentionPooling(2048)\n",
                "        \n",
                "        self.freeze_layers = freeze_layers or []\n",
                "        self._freeze()\n",
                "\n",
                "    def _freeze(self):\n",
                "        freeze_map = {\n",
                "            \"conv1\": [self.conv1, self.bn1],\n",
                "            \"layer1\": [self.layer1],\n",
                "            \"layer2\": [self.layer2],\n",
                "            \"layer3\": [self.layer3],\n",
                "            \"layer4\": [self.layer4],\n",
                "        }\n",
                "        for name in self.freeze_layers:\n",
                "            if name in freeze_map:\n",
                "                for module in freeze_map[name]:\n",
                "                    for p in module.parameters():\n",
                "                        p.requires_grad = False\n",
                "\n",
                "    def forward(self, x):\n",
                "        x = self.relu(self.bn1(self.conv1(x)))\n",
                "        x = self.layer1(x)\n",
                "        x = self.layer2(x)\n",
                "        x = self.layer3(x)\n",
                "        x = self.layer4(x)\n",
                "        \n",
                "        x = self.dropout(x)\n",
                "        \n",
                "        patch_logits = self.patch_classifier(x)\n",
                "        pooled_logits, attn = self.attention_pool(x, patch_logits)\n",
                "        pooled_logits = pooled_logits.view(-1)\n",
                "        \n",
                "        return pooled_logits, patch_logits, attn\n",
                "\n",
                "print(\"Model class defined.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Metrics and Training Functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def compute_metrics(preds, labels, probs=None) -> Dict:\n",
                "    \"\"\"Compute classification metrics.\"\"\"\n",
                "    preds = np.asarray(preds).astype(int)\n",
                "    labels = np.asarray(labels).astype(int)\n",
                "    \n",
                "    acc = (preds == labels).mean()\n",
                "    tp = ((preds == 1) & (labels == 1)).sum()\n",
                "    fp = ((preds == 1) & (labels == 0)).sum()\n",
                "    fn = ((preds == 0) & (labels == 1)).sum()\n",
                "    \n",
                "    prec = tp / (tp + fp + 1e-8)\n",
                "    rec = tp / (tp + fn + 1e-8)\n",
                "    f1 = 2 * prec * rec / (prec + rec + 1e-8)\n",
                "    \n",
                "    metrics = {\"accuracy\": float(acc), \"precision\": float(prec), \"recall\": float(rec), \"f1\": float(f1)}\n",
                "    \n",
                "    if probs is not None:\n",
                "        try:\n",
                "            from sklearn.metrics import roc_auc_score\n",
                "            metrics[\"auc\"] = float(roc_auc_score(labels, probs))\n",
                "        except Exception:\n",
                "            pass\n",
                "    \n",
                "    return metrics\n",
                "\n",
                "\n",
                "def train_epoch(model, dataloader, criterion, optimizer, scaler, device):\n",
                "    \"\"\"Train for one epoch.\"\"\"\n",
                "    model.train()\n",
                "    total_loss = 0.0\n",
                "    all_probs, all_labels = [], []\n",
                "    \n",
                "    pbar = tqdm(dataloader, desc=\"Training\", leave=False)\n",
                "    for batch in pbar:\n",
                "        images = batch[\"image\"].to(device, non_blocking=True)\n",
                "        labels = batch[\"label\"].to(device, non_blocking=True).float()\n",
                "        \n",
                "        optimizer.zero_grad(set_to_none=True)\n",
                "        \n",
                "        with autocast(enabled=(device.type == \"cuda\")):\n",
                "            pooled, _, _ = model(images)\n",
                "            pooled = pooled.view(-1)\n",
                "            loss = criterion(pooled, labels)\n",
                "        \n",
                "        scaler.scale(loss).backward()\n",
                "        scaler.unscale_(optimizer)\n",
                "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
                "        scaler.step(optimizer)\n",
                "        scaler.update()\n",
                "        \n",
                "        total_loss += loss.item() * labels.size(0)\n",
                "        probs = torch.sigmoid(pooled).detach().view(-1).cpu().numpy()\n",
                "        all_probs.extend(probs.tolist())\n",
                "        all_labels.extend(labels.detach().cpu().numpy().tolist())\n",
                "        \n",
                "        pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
                "    \n",
                "    all_probs = np.asarray(all_probs)\n",
                "    all_labels = np.asarray(all_labels)\n",
                "    \n",
                "    metrics = compute_metrics((all_probs > 0.5).astype(int), all_labels, all_probs)\n",
                "    metrics[\"loss\"] = total_loss / len(all_labels)\n",
                "    return metrics\n",
                "\n",
                "\n",
                "def validate(model, dataloader, criterion, device):\n",
                "    \"\"\"Validate the model.\"\"\"\n",
                "    model.eval()\n",
                "    total_loss = 0.0\n",
                "    all_probs, all_labels = [], []\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        for batch in tqdm(dataloader, desc=\"Validation\", leave=False):\n",
                "            images = batch[\"image\"].to(device, non_blocking=True)\n",
                "            labels = batch[\"label\"].to(device, non_blocking=True).float()\n",
                "            \n",
                "            pooled, _, _ = model(images)\n",
                "            pooled = pooled.view(-1)\n",
                "            loss = criterion(pooled, labels)\n",
                "            \n",
                "            total_loss += loss.item() * labels.size(0)\n",
                "            probs = torch.sigmoid(pooled).view(-1).cpu().numpy()\n",
                "            all_probs.extend(probs.tolist())\n",
                "            all_labels.extend(labels.cpu().numpy().tolist())\n",
                "    \n",
                "    all_probs = np.asarray(all_probs)\n",
                "    all_labels = np.asarray(all_labels)\n",
                "    \n",
                "    metrics = compute_metrics((all_probs > 0.5).astype(int), all_labels, all_probs)\n",
                "    metrics[\"loss\"] = total_loss / len(all_labels)\n",
                "    return metrics\n",
                "\n",
                "print(\"Training functions defined.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Load Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Setup directories\n",
                "os.makedirs(config.output_dir, exist_ok=True)\n",
                "checkpoint_dir = os.path.join(config.output_dir, \"checkpoints\")\n",
                "os.makedirs(checkpoint_dir, exist_ok=True)\n",
                "\n",
                "# Device\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"Using device: {device}\")\n",
                "\n",
                "# Load data\n",
                "print(\"\\nLoading dataset...\")\n",
                "data_root = Path(config.data_path)\n",
                "\n",
                "train_images = load_split(data_root, \"train\")\n",
                "val_images = load_split(data_root, \"val\")\n",
                "test_images = load_split(data_root, \"test\")\n",
                "\n",
                "print(f\"  Train: {len(train_images)} images\")\n",
                "print(f\"  Val: {len(val_images)} images\")\n",
                "print(f\"  Test: {len(test_images)} images\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create datasets\n",
                "print(\"Creating datasets...\")\n",
                "train_dataset = DeepfakeDataset(train_images, augment=True, augment_config=augment_config)\n",
                "val_dataset = DeepfakeDataset(val_images, augment=False)\n",
                "test_dataset = DeepfakeDataset(test_images, augment=False)\n",
                "\n",
                "# Create dataloaders\n",
                "train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, \n",
                "                          num_workers=config.num_workers, pin_memory=True, drop_last=True, collate_fn=collate_fn)\n",
                "val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False,\n",
                "                        num_workers=config.num_workers, pin_memory=True, collate_fn=collate_fn)\n",
                "test_loader = DataLoader(test_dataset, batch_size=config.batch_size, shuffle=False,\n",
                "                         num_workers=config.num_workers, pin_memory=True, collate_fn=collate_fn)\n",
                "\n",
                "print(f\"\\nDataLoaders: {len(train_loader)} train, {len(val_loader)} val, {len(test_loader)} test batches\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Initialize Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Initializing model...\")\n",
                "model = LaDeDaResNet50(pretrained=True, freeze_layers=config.freeze_layers, dropout_rate=config.dropout_rate)\n",
                "model = model.to(device)\n",
                "\n",
                "total_params = sum(p.numel() for p in model.parameters())\n",
                "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
                "print(f\"  Total params: {total_params:,}\")\n",
                "print(f\"  Trainable: {trainable_params:,} ({100*trainable_params/total_params:.1f}%)\")\n",
                "print(f\"  Frozen: {total_params - trainable_params:,} ({100*(total_params-trainable_params)/total_params:.1f}%)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 11. Setup Optimizer and Scheduler"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "criterion = nn.BCEWithLogitsLoss()\n",
                "optimizer = optim.AdamW(\n",
                "    filter(lambda p: p.requires_grad, model.parameters()),\n",
                "    lr=config.lr,\n",
                "    weight_decay=config.weight_decay\n",
                ")\n",
                "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=2, eta_min=1e-6)\n",
                "scaler = GradScaler()\n",
                "\n",
                "print(\"Optimizer: AdamW\")\n",
                "print(f\"  Learning rate: {config.lr}\")\n",
                "print(f\"  Weight decay: {config.weight_decay}\")\n",
                "print(\"Scheduler: CosineAnnealingWarmRestarts\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 12. Training Loop with Early Stopping and Checkpoints\n",
                "\n",
                "This cell runs the main training loop. Progress is saved after each epoch."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize tracking variables\n",
                "best_val_loss = float('inf')\n",
                "best_val_f1 = 0\n",
                "epochs_without_improvement = 0\n",
                "history = {\"train\": [], \"val\": []}\n",
                "start_time = time.time()\n",
                "\n",
                "print(\"=\" * 60)\n",
                "print(\"TRAINING\")\n",
                "print(\"=\" * 60)\n",
                "print(f\"Early stopping patience: {config.early_stopping_patience} epochs\")\n",
                "print()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Main training loop - Run this cell to train\n",
                "# You can re-run this cell to continue training from last checkpoint\n",
                "\n",
                "for epoch in range(len(history[\"train\"]), config.epochs):\n",
                "    print(f\"\\nEpoch {epoch + 1}/{config.epochs}\")\n",
                "    print(\"-\" * 40)\n",
                "    \n",
                "    # Train\n",
                "    train_metrics = train_epoch(model, train_loader, criterion, optimizer, scaler, device)\n",
                "    \n",
                "    # Validate\n",
                "    val_metrics = validate(model, val_loader, criterion, device)\n",
                "    \n",
                "    scheduler.step()\n",
                "    \n",
                "    history[\"train\"].append(train_metrics)\n",
                "    history[\"val\"].append(val_metrics)\n",
                "    \n",
                "    print(f\"Train | Loss: {train_metrics['loss']:.4f} | Acc: {train_metrics['accuracy']:.4f} | F1: {train_metrics['f1']:.4f}\")\n",
                "    print(f\"Val   | Loss: {val_metrics['loss']:.4f} | Acc: {val_metrics['accuracy']:.4f} | F1: {val_metrics['f1']:.4f}\")\n",
                "    \n",
                "    # Early stopping check\n",
                "    if val_metrics[\"loss\"] < best_val_loss:\n",
                "        best_val_loss = val_metrics[\"loss\"]\n",
                "        epochs_without_improvement = 0\n",
                "        print(f\"âœ“ New best val loss: {best_val_loss:.4f}\")\n",
                "    else:\n",
                "        epochs_without_improvement += 1\n",
                "        print(f\"âš  No improvement for {epochs_without_improvement}/{config.early_stopping_patience} epochs\")\n",
                "    \n",
                "    # Save best model\n",
                "    if val_metrics[\"f1\"] > best_val_f1:\n",
                "        best_val_f1 = val_metrics[\"f1\"]\n",
                "        torch.save({\n",
                "            \"epoch\": epoch,\n",
                "            \"model_state_dict\": model.state_dict(),\n",
                "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
                "            \"scheduler_state_dict\": scheduler.state_dict(),\n",
                "            \"val_metrics\": val_metrics,\n",
                "            \"history\": history,\n",
                "        }, os.path.join(checkpoint_dir, \"best_model.pth\"))\n",
                "        print(f\"ðŸ’¾ Saved best model (Val F1: {best_val_f1:.4f})\")\n",
                "    \n",
                "    # Save latest checkpoint (for resuming)\n",
                "    torch.save({\n",
                "        \"epoch\": epoch,\n",
                "        \"model_state_dict\": model.state_dict(),\n",
                "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
                "        \"scheduler_state_dict\": scheduler.state_dict(),\n",
                "        \"best_val_loss\": best_val_loss,\n",
                "        \"best_val_f1\": best_val_f1,\n",
                "        \"epochs_without_improvement\": epochs_without_improvement,\n",
                "        \"history\": history,\n",
                "    }, os.path.join(checkpoint_dir, \"latest_checkpoint.pth\"))\n",
                "    \n",
                "    # Early stopping\n",
                "    if epochs_without_improvement >= config.early_stopping_patience:\n",
                "        print(f\"\\nðŸ›‘ Early stopping triggered! No improvement for {config.early_stopping_patience} epochs.\")\n",
                "        break\n",
                "\n",
                "total_time = time.time() - start_time\n",
                "print(f\"\\n{'='*60}\")\n",
                "print(f\"Training complete in {total_time/60:.1f} minutes\")\n",
                "print(f\"Best Val F1: {best_val_f1:.4f}\")\n",
                "print(f\"Best Val Loss: {best_val_loss:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 13. Plot Training History"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
                "\n",
                "# Loss\n",
                "axes[0].plot([m['loss'] for m in history['train']], 'b-', label='Train', linewidth=2)\n",
                "axes[0].plot([m['loss'] for m in history['val']], 'r-', label='Val', linewidth=2)\n",
                "axes[0].set_xlabel('Epoch')\n",
                "axes[0].set_ylabel('Loss')\n",
                "axes[0].set_title('Loss')\n",
                "axes[0].legend()\n",
                "axes[0].grid(True, alpha=0.3)\n",
                "\n",
                "# Accuracy\n",
                "axes[1].plot([m['accuracy'] for m in history['train']], 'b-', label='Train', linewidth=2)\n",
                "axes[1].plot([m['accuracy'] for m in history['val']], 'r-', label='Val', linewidth=2)\n",
                "axes[1].set_xlabel('Epoch')\n",
                "axes[1].set_ylabel('Accuracy')\n",
                "axes[1].set_title('Accuracy')\n",
                "axes[1].legend()\n",
                "axes[1].grid(True, alpha=0.3)\n",
                "\n",
                "# F1\n",
                "axes[2].plot([m['f1'] for m in history['train']], 'b-', label='Train', linewidth=2)\n",
                "axes[2].plot([m['f1'] for m in history['val']], 'r-', label='Val', linewidth=2)\n",
                "axes[2].set_xlabel('Epoch')\n",
                "axes[2].set_ylabel('F1 Score')\n",
                "axes[2].set_title('F1 Score')\n",
                "axes[2].legend()\n",
                "axes[2].grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(os.path.join(config.output_dir, \"training_history.png\"), dpi=150, bbox_inches='tight')\n",
                "plt.show()\n",
                "print(f\"Training history saved to: {os.path.join(config.output_dir, 'training_history.png')}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 14. Load Best Model and Evaluate on Test Set"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Loading best model for evaluation...\")\n",
                "checkpoint = torch.load(os.path.join(checkpoint_dir, \"best_model.pth\"), map_location=device)\n",
                "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
                "print(f\"Loaded model from epoch {checkpoint['epoch'] + 1}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def evaluate(model, dataloader, device):\n",
                "    \"\"\"Evaluate the model.\"\"\"\n",
                "    model.eval()\n",
                "    all_probs, all_labels = [], []\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        for batch in tqdm(dataloader, desc=\"Evaluating\", leave=False):\n",
                "            images = batch[\"image\"].to(device)\n",
                "            labels = batch[\"label\"].cpu().numpy().astype(int)\n",
                "            \n",
                "            pooled, _, _ = model(images)\n",
                "            probs = torch.sigmoid(pooled).view(-1).cpu().numpy()\n",
                "            \n",
                "            all_probs.extend(probs.tolist())\n",
                "            all_labels.extend(labels.tolist())\n",
                "    \n",
                "    all_probs = np.asarray(all_probs)\n",
                "    all_labels = np.asarray(all_labels)\n",
                "    \n",
                "    return compute_metrics((all_probs > 0.5).astype(int), all_labels, all_probs)\n",
                "\n",
                "print(\"\\n\" + \"=\" * 60)\n",
                "print(\"FINAL EVALUATION\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "test_metrics = evaluate(model, test_loader, device)\n",
                "print(f\"\\nTest Results:\")\n",
                "print(f\"  Accuracy:  {test_metrics['accuracy']:.4f}\")\n",
                "print(f\"  Precision: {test_metrics['precision']:.4f}\")\n",
                "print(f\"  Recall:    {test_metrics['recall']:.4f}\")\n",
                "print(f\"  F1:        {test_metrics['f1']:.4f}\")\n",
                "if \"auc\" in test_metrics:\n",
                "    print(f\"  AUC:       {test_metrics['auc']:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 15. Save Final Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "results = {\n",
                "    \"config\": {\n",
                "        \"epochs_trained\": len(history[\"train\"]),\n",
                "        \"max_epochs\": config.epochs,\n",
                "        \"batch_size\": config.batch_size,\n",
                "        \"lr\": config.lr,\n",
                "        \"weight_decay\": config.weight_decay,\n",
                "        \"dropout_rate\": config.dropout_rate,\n",
                "        \"early_stopping_patience\": config.early_stopping_patience,\n",
                "        \"frozen_layers\": config.freeze_layers,\n",
                "    },\n",
                "    \"best_val_f1\": best_val_f1,\n",
                "    \"best_val_loss\": best_val_loss,\n",
                "    \"test_metrics\": test_metrics,\n",
                "    \"training_time_minutes\": total_time / 60,\n",
                "}\n",
                "\n",
                "with open(os.path.join(config.output_dir, \"results.json\"), \"w\") as f:\n",
                "    json.dump(results, f, indent=2)\n",
                "\n",
                "print(f\"Results saved to: {os.path.join(config.output_dir, 'results.json')}\")\n",
                "print(f\"\\nâœ… Training complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Optional: Resume Training from Checkpoint\n",
                "\n",
                "Run this cell if you need to resume training after a kernel restart."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Uncomment and run to resume from latest checkpoint\n",
                "\n",
                "# checkpoint_path = os.path.join(checkpoint_dir, \"latest_checkpoint.pth\")\n",
                "# if os.path.exists(checkpoint_path):\n",
                "#     checkpoint = torch.load(checkpoint_path, map_location=device)\n",
                "#     model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
                "#     optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
                "#     scheduler.load_state_dict(checkpoint[\"scheduler_state_dict\"])\n",
                "#     best_val_loss = checkpoint[\"best_val_loss\"]\n",
                "#     best_val_f1 = checkpoint[\"best_val_f1\"]\n",
                "#     epochs_without_improvement = checkpoint[\"epochs_without_improvement\"]\n",
                "#     history = checkpoint[\"history\"]\n",
                "#     print(f\"Resumed from epoch {checkpoint['epoch'] + 1}\")\n",
                "#     print(f\"Best val F1: {best_val_f1:.4f}, Best val loss: {best_val_loss:.4f}\")\n",
                "# else:\n",
                "#     print(\"No checkpoint found.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}