{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# FF++ Pipeline Audit - Step 7 & Step 8 Verification\n",
                "\n",
                "This notebook verifies:\n",
                "- **Step 7**: Constrained batching (method mixing, video_id anti-correlation)\n",
                "- **Step 8**: Deployment realism augmentations\n",
                "- **Lazy caching**: Cache hit/miss rates"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 1. Clone Repository"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "!git clone https://github.com/Incharajayaram/Team-Converge.git /content/Team-Converge\n",
                "%cd /content/Team-Converge/Finetune1"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 2. Install Dependencies"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "!pip install -q mediapipe pyyaml tqdm"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 3. Upload FF++ Data (ZIP file)\n",
                "\n",
                "Upload your `ffpp_data.zip` file when prompted. The zip should contain the raw FF++ videos."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "from google.colab import files\n",
                "import os\n",
                "\n",
                "print(\"Upload your ffpp_data.zip file...\")\n",
                "uploaded = files.upload()\n",
                "\n",
                "# Get the uploaded filename\n",
                "zip_filename = list(uploaded.keys())[0]\n",
                "print(f\"Uploaded: {zip_filename}\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Extract to /content/data/raw/ffpp\n",
                "!mkdir -p /content/data/raw/ffpp\n",
                "!unzip -q \"{zip_filename}\" -d /content/data/raw/ffpp\n",
                "!ls -la /content/data/raw/ffpp | head -20\n",
                "print(f\"\\nTotal files: {len(os.listdir('/content/data/raw/ffpp'))}\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 4. Run Audit Mode (300 steps)\n",
                "\n",
                "This will:\n",
                "- Validate Step 7 batch constraints every 25 batches\n",
                "- Dump 32 augmented samples for visual inspection\n",
                "- Track cache hit/miss rates"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "!python train.py --config config.yaml \\\n",
                "    --override dataset.ffpp_root=/content/data/raw/ffpp \\\n",
                "    --override caching.cache_dir=/content/cache/faces \\\n",
                "    --audit_steps 300 \\\n",
                "    --audit_every 25 \\\n",
                "    --dump_aug 32"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 5. View Audit Report"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "import json\n",
                "with open('artifacts/reports/audit_report.json') as f:\n",
                "    report = json.load(f)\n",
                "    \n",
                "print(\"=\" * 50)\n",
                "print(\"AUDIT REPORT SUMMARY\")\n",
                "print(\"=\" * 50)\n",
                "print(f\"Total batches: {report['total_batches']}\")\n",
                "print(f\"Valid batches: {report['valid_batches']} ({100*report['valid_batches']/report['total_batches']:.1f}%)\")\n",
                "print(f\"Method mixing OK: {report['method_mixing_ok']}\")\n",
                "print(f\"Video ID violations: {report['video_violations']}\")\n",
                "print(f\"Group ID violations: {report['group_violations']}\")\n",
                "print(f\"Group relaxed (fallback): {report['group_relaxed']}\")\n",
                "print(f\"\\nCache hit rate: {report['cache_hit_rate']:.2%}\")\n",
                "print(f\"Avg data_time: {report['avg_data_time']:.3f}s\")\n",
                "print(f\"Avg step_time: {report['avg_step_time']:.3f}s\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 6. View Augmented Samples (Step 8 Visual Check)"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "import matplotlib.pyplot as plt\n",
                "from PIL import Image\n",
                "import os\n",
                "\n",
                "aug_dir = 'artifacts/aug_debug'\n",
                "files = sorted(os.listdir(aug_dir))[:16]\n",
                "\n",
                "fig, axes = plt.subplots(4, 4, figsize=(16, 16))\n",
                "for ax, fname in zip(axes.flat, files):\n",
                "    img = Image.open(os.path.join(aug_dir, fname))\n",
                "    ax.imshow(img)\n",
                "    ax.set_title(fname[:30], fontsize=8)\n",
                "    ax.axis('off')\n",
                "plt.tight_layout()\n",
                "plt.savefig('artifacts/aug_grid.png', dpi=150)\n",
                "plt.show()\n",
                "\n",
                "print(f\"\\nTotal augmented samples: {len(os.listdir(aug_dir))}\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 7. Check Cache"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "cache_dir = '/content/cache/faces/train'\n",
                "if os.path.exists(cache_dir):\n",
                "    files = os.listdir(cache_dir)\n",
                "    print(f\"Cached face crops: {len(files)}\")\n",
                "    sizes = [os.path.getsize(os.path.join(cache_dir, f)) for f in files[:100]]\n",
                "    print(f\"Avg size: {sum(sizes)/len(sizes)/1024:.1f} KB\")\n",
                "else:\n",
                "    print(\"No cache yet\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        }
    ]
}