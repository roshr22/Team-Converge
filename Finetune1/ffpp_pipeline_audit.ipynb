{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# FF++ Pipeline Audit - Step 7 & Step 8 Verification"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "# 1. Mount Drive\n",
                "from google.colab import drive\n",
                "drive.mount('/content/drive')"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# 2. Clone repo\n",
                "!git clone https://github.com/Incharajayaram/Team-Converge.git /content/Team-Converge\n",
                "%cd /content/Team-Converge/Finetune1\n",
                "!pip install -q mediapipe pyyaml tqdm"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# 3. Download FF++ data from Drive (with large file handling)\n",
                "import os\n",
                "import subprocess\n",
                "\n",
                "FILE_ID = \"1zdmdO0_rUyMspOkZtAi3b0oN_NOxYyLm\"\n",
                "ZIP_PATH = \"/content/ffpp_data.zip\"\n",
                "\n",
                "# Remove any corrupted previous download\n",
                "if os.path.exists(ZIP_PATH):\n",
                "    os.remove(ZIP_PATH)\n",
                "\n",
                "# Use gdown with confirm flag for large files\n",
                "!pip install -q --upgrade gdown\n",
                "!gdown --id {FILE_ID} --output {ZIP_PATH} --fuzzy\n",
                "\n",
                "# Verify download\n",
                "size_gb = os.path.getsize(ZIP_PATH) / 1e9\n",
                "print(f\"\\nDownloaded: {size_gb:.2f} GB\")\n",
                "if size_gb < 1.0:\n",
                "    print(\"WARNING: File seems too small! Download may have failed.\")\n",
                "    print(\"Try: !cp '/content/drive/MyDrive/YOUR_PATH/ffpp_data.zip' /content/ffpp_data.zip\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# 4. Extract to local disk\n",
                "!mkdir -p /content/data/raw/ffpp\n",
                "!unzip -q /content/ffpp_data.zip -d /content/data/raw/ffpp\n",
                "!ls /content/data/raw/ffpp | head -10\n",
                "print(f\"Total items: {len(os.listdir('/content/data/raw/ffpp'))}\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# 5. Run Audit (300 steps)\n",
                "!python train.py --config config.yaml \\\n",
                "    --override dataset.ffpp_root=/content/data/raw/ffpp \\\n",
                "    --override caching.cache_dir=/content/cache/faces \\\n",
                "    --audit_steps 300 --audit_every 25 --dump_aug 32"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# 6. View Audit Report\n",
                "import json\n",
                "with open('artifacts/reports/audit_report.json') as f:\n",
                "    r = json.load(f)\n",
                "print(f\"Valid batches: {r['valid_batches']}/{r['total_batches']}\")\n",
                "print(f\"Video violations: {r['video_violations']}\")\n",
                "print(f\"Group violations: {r['group_violations']}\")\n",
                "print(f\"Cache hit rate: {r['cache_hit_rate']:.2%}\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# 7. View Augmented Samples\n",
                "import matplotlib.pyplot as plt\n",
                "from PIL import Image\n",
                "aug_dir = 'artifacts/aug_debug'\n",
                "files = sorted(os.listdir(aug_dir))[:16]\n",
                "fig, axes = plt.subplots(4, 4, figsize=(14, 14))\n",
                "for ax, f in zip(axes.flat, files):\n",
                "    ax.imshow(Image.open(f'{aug_dir}/{f}'))\n",
                "    ax.set_title(f[:25], fontsize=7)\n",
                "    ax.axis('off')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        }
    ]
}