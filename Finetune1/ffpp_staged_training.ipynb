{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# FF++ Staged Fine-tuning (FAST Version)\n",
                "\n",
                "**Key optimization**: Pre-extract all faces BEFORE training.\n",
                "\n",
                "| Phase | Time |\n",
                "|-------|------|\n",
                "| Pre-extraction | ~30-45 min (one-time) |\n",
                "| Stage A (2 epochs) | ~30 min |\n",
                "| Stage B (8 epochs) | ~2 hrs |\n",
                "| **Total** | **~3-4 hours** |\n",
                "\n",
                "Compare to on-the-fly extraction: ~19 hours"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "# 1. GPU Check\n",
                "import torch\n",
                "if not torch.cuda.is_available():\n",
                "    raise SystemExit(\"GPU required! Go to Runtime > Change runtime type > GPU\")\n",
                "print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# 2. Mount Drive & Clone Repo\n",
                "from google.colab import drive\n",
                "drive.mount('/content/drive')\n",
                "\n",
                "!rm -rf /content/Team-Converge\n",
                "!git clone https://github.com/Incharajayaram/Team-Converge.git /content/Team-Converge\n",
                "%cd /content/Team-Converge/Finetune1"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# 3. Install Dependencies\n",
                "!pip install -q mediapipe pyyaml tqdm gdown scikit-learn"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# 4. Download FF++ Data (17GB)\n",
                "import os\n",
                "\n",
                "# Option 1: Copy from user's Drive (Reliable \"Trick\")\n",
                "# This bypasses the \"Too many users have viewed...\" error\n",
                "if os.path.exists('/content/drive/MyDrive/ffpp_data_new.zip'):\n",
                "    print(\"Copying from Drive (Fast & Reliable)...\")\n",
                "    !cp '/content/drive/MyDrive/ffpp_data_new.zip' /content/ffpp_data.zip\n",
                "elif os.path.exists('/content/drive/MyDrive/ffpp_data.zip'):\n",
                "    print(\"Copying from Drive (Fast & Reliable)...\")\n",
                "    !cp '/content/drive/MyDrive/ffpp_data.zip' /content/ffpp_data.zip\n",
                "else: \n",
                "    # Option 2: Download from link (Prone to rate limits)\n",
                "    print(\"File not found in Drive. Attempting download (may fail with rate limit)...\")\n",
                "    FILE_ID = \"1a7X9Cjv3gsj4qC6kcDq6VLNl7eR3osoy\"\n",
                "    ZIP_PATH = \"/content/ffpp_data.zip\"\n",
                "    !pip install -q --upgrade gdown\n",
                "    !gdown --id {FILE_ID} --output {ZIP_PATH} --fuzzy\n",
                "\n",
                "ZIP_PATH = \"/content/ffpp_data.zip\"\n",
                "if os.path.exists(ZIP_PATH):\n",
                "    size_gb = os.path.getsize(ZIP_PATH) / 1e9\n",
                "    print(f\"File size: {size_gb:.2f} GB\")\n",
                "    if size_gb < 15:\n",
                "        raise ValueError(f\"Download incomplete! Only {size_gb:.2f} GB. Try copying manually to Drive first.\")\n",
                "else:\n",
                "    raise FileNotFoundError(\"ffpp_data.zip not found! Upload 'ffpp_data_new.zip' to your Drive root.\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# 5. Extract Data\n",
                "!rm -rf /content/data/raw/ffpp\n",
                "!mkdir -p /content/data/raw/ffpp\n",
                "!unzip -q /content/ffpp_data.zip -d /content/data/raw/ffpp\n",
                "\n",
                "import os\n",
                "FFPP_ROOT = \"/content/data/raw/ffpp/FaceForensics++_C23\"\n",
                "if not os.path.exists(FFPP_ROOT):\n",
                "    FFPP_ROOT = \"/content/data/raw/ffpp\"\n",
                "os.environ['FFPP_ROOT'] = FFPP_ROOT\n",
                "print(f\"FFPP_ROOT: {FFPP_ROOT}\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# 6. Generate Video Index\n",
                "import os\n",
                "os.chdir('/content/Team-Converge/Finetune1')\n",
                "\n",
                "from pathlib import Path\n",
                "from utils.indexing import build_master_index\n",
                "\n",
                "FFPP_ROOT = os.environ.get('FFPP_ROOT')\n",
                "output_csv = Path(\"data/index/videos_master.csv\")\n",
                "output_csv.parent.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "videos = build_master_index(ffpp_root=Path(FFPP_ROOT), output_path=output_csv)\n",
                "print(f\"Indexed {len(videos)} videos\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# 7. Generate Fast Manifests (no ffprobe)\n",
                "import csv\n",
                "from pathlib import Path\n",
                "from utils.indexing import load_master_index\n",
                "from utils.face_extraction import generate_sample_id\n",
                "\n",
                "videos = load_master_index(Path(\"data/index/videos_master.csv\"))\n",
                "\n",
                "samples = []\n",
                "for v in videos:\n",
                "    k = 10 if v.split != 'test' else 20\n",
                "    for i in range(k):\n",
                "        ts = 0.5 + i * 0.8\n",
                "        samples.append({\n",
                "            'sample_id': generate_sample_id(),\n",
                "            'dataset': v.dataset, 'split': v.split, 'label': v.label,\n",
                "            'method': v.method, 'group_id': v.group_id,\n",
                "            'video_id': v.video_id, 'video_path': v.video_path,\n",
                "            'timestamp': ts, 'filepath': ''\n",
                "        })\n",
                "\n",
                "out_dir = Path('artifacts/manifests')\n",
                "out_dir.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "for split in ['train', 'val', 'test']:\n",
                "    split_samples = [s for s in samples if s['split'] == split]\n",
                "    with open(out_dir / f'{split}.csv', 'w', newline='') as f:\n",
                "        w = csv.DictWriter(f, fieldnames=list(samples[0].keys()))\n",
                "        w.writeheader()\n",
                "        w.writerows(split_samples)\n",
                "    print(f\"{split}: {len(split_samples)} samples\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# 8. PRE-EXTRACT ALL FACES (30-45 min, CRITICAL for fast training!)\n",
                "import os\n",
                "FFPP_ROOT = os.environ.get('FFPP_ROOT', '/content/data/raw/ffpp/FaceForensics++_C23')\n",
                "\n",
                "print(\"=\"*60)\n",
                "print(\"PRE-EXTRACTING FACES (this takes 30-45 min)\")\n",
                "print(\"This is a ONE-TIME cost that makes training 10x faster!\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "# Extract train faces\n",
                "!python preextract_faces.py \\\n",
                "    --ffpp_root {FFPP_ROOT} \\\n",
                "    --manifest artifacts/manifests/train.csv \\\n",
                "    --cache_dir /content/cache/faces \\\n",
                "    --workers 8\n",
                "\n",
                "# Extract val faces\n",
                "!python preextract_faces.py \\\n",
                "    --ffpp_root {FFPP_ROOT} \\\n",
                "    --manifest artifacts/manifests/val.csv \\\n",
                "    --cache_dir /content/cache/faces \\\n",
                "    --workers 8\n",
                "\n",
                "print(\"\\nPre-extraction complete! Training will be FAST now.\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# 9. Create output directories\n",
                "!mkdir -p /content/drive/MyDrive/ffpp_training/staged\n",
                "!mkdir -p /content/cache/faces\n",
                "print(\"Output dir: /content/drive/MyDrive/ffpp_training/staged\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# 10. Stage A: Head-only training (2 epochs) - NOW FAST!\n",
                "import os\n",
                "FFPP_ROOT = os.environ.get('FFPP_ROOT', '/content/data/raw/ffpp/FaceForensics++_C23')\n",
                "\n",
                "print(\"=\"*60)\n",
                "print(\"STAGE A: Head-only training (2 epochs)\")\n",
                "print(\"Expected time: ~30 min (faces are pre-extracted!)\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "!python train_staged.py --config config.yaml \\\n",
                "    --override dataset.ffpp_root={FFPP_ROOT} \\\n",
                "    --override caching.cache_dir=/content/cache/faces \\\n",
                "    --stages A \\\n",
                "    --output_dir /content/drive/MyDrive/ffpp_training/staged"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# 11. Stage B: Partial unfreeze (8 epochs)\n",
                "import os\n",
                "FFPP_ROOT = os.environ.get('FFPP_ROOT', '/content/data/raw/ffpp/FaceForensics++_C23')\n",
                "\n",
                "checkpoint = \"/content/drive/MyDrive/ffpp_training/staged/best_model.pt\"\n",
                "if not os.path.exists(checkpoint):\n",
                "    raise FileNotFoundError(f\"Stage A checkpoint not found: {checkpoint}\")\n",
                "\n",
                "print(\"=\"*60)\n",
                "print(\"STAGE B: Partial unfreeze - layer4 (8 epochs)\")\n",
                "print(\"Expected time: ~2 hrs\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "!python train_staged.py --config config.yaml \\\n",
                "    --override dataset.ffpp_root={FFPP_ROOT} \\\n",
                "    --override caching.cache_dir=/content/cache/faces \\\n",
                "    --stages B \\\n",
                "    --resume {checkpoint} \\\n",
                "    --output_dir /content/drive/MyDrive/ffpp_training/staged"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# 12. View Training History\n",
                "import json\n",
                "import matplotlib.pyplot as plt\n",
                "import os\n",
                "\n",
                "history_path = '/content/drive/MyDrive/ffpp_training/staged/training_history.json'\n",
                "if os.path.exists(history_path):\n",
                "    with open(history_path) as f:\n",
                "        history = json.load(f)\n",
                "    \n",
                "    epochs = [h['epoch'] for h in history]\n",
                "    train_loss = [h['train_loss'] for h in history]\n",
                "    val_loss = [h['val_loss'] for h in history]\n",
                "    val_auc = [h.get('val_auc', 0.5) for h in history]\n",
                "    \n",
                "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
                "    ax1.plot(epochs, train_loss, 'b-', label='Train')\n",
                "    ax1.plot(epochs, val_loss, 'r-', label='Val')\n",
                "    ax1.set_xlabel('Epoch'); ax1.set_ylabel('Loss'); ax1.legend(); ax1.grid(True)\n",
                "    ax2.plot(epochs, val_auc, 'g-'); ax2.set_ylim(0.5, 1.0)\n",
                "    ax2.set_xlabel('Epoch'); ax2.set_ylabel('AUC'); ax2.grid(True)\n",
                "    plt.tight_layout(); plt.show()\n",
                "    \n",
                "    print(f\"Best val_loss: {min(val_loss):.4f}\")\n",
                "    print(f\"Best val_auc: {max(val_auc):.4f}\")\n",
                "else:\n",
                "    print(f\"History not found: {history_path}\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# 13. Save Final Model\n",
                "import shutil\n",
                "import os\n",
                "\n",
                "src = '/content/drive/MyDrive/ffpp_training/staged/best_model.pt'\n",
                "dst = '/content/drive/MyDrive/ffpp_training/final_model.pt'\n",
                "\n",
                "if os.path.exists(src):\n",
                "    shutil.copy(src, dst)\n",
                "    print(f\"Saved: {dst}\")\n",
                "    print(f\"Size: {os.path.getsize(dst)/1e6:.1f} MB\")\n",
                "else:\n",
                "    print(f\"Model not found: {src}\")\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"TRAINING COMPLETE!\")\n",
                "print(\"=\"*60)"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        }
    ]
}